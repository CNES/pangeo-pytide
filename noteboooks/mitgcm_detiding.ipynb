{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of simulated tidal waves in the MIT/GCM/LLC4320 model\n",
    "\n",
    "In this example, we will estimate the tidal waves generated by the model. To do this we have to process the time series consisting of a 2D grid set. This set is stored as a 3D cube of 242'611'200 pixels per face stacked in 7566 layers. Each layer represents a date of the simulation. This cube is stored in Zarr format and represents about 7 TB.\n",
    "\n",
    "![cube](cube.png \"Chart representation of the cube formed by the grids.\")\n",
    "\n",
    "This analysis consists of performing a harmonic analysis on a time series of the cube. This time series is shown in yellow in the figure below. To perform this analysis, we must perform this analysis on all the pixels of the faces, i.e. 242 million times. It will also be necessary to modify the shape of the cube in memory to optimize data access during analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.distributed\n",
    "import intake\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of the calculation period of the analysis (the spin-up period is not included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = np.datetime64('2011-11-13')\n",
    "END_DATE = np.datetime64('2012-11-12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_url = \"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean/llc4320.yaml\"\n",
    "cat = intake.Catalog(cat_url)\n",
    "\n",
    "ssh = cat.LLC4320_SSH.to_dask()\n",
    "ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selection of the computation time series (the spin-off period of the model is skipped)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = ssh.time.values\n",
    "period = (time_series >= START_DATE) & (time_series <= END_DATE)\n",
    "print(\"number of layers to process %d\" % len(time_series[period]))\n",
    "print(\"period [%s, %s]\" % (time_series[period].min(), time_series[period].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the object controlling the harmonic analysis of the waves M2, K1, O1, P1, S1, S2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytide\n",
    "\n",
    "wave_table = pytide.WaveTable(['M2', 'K1', 'O1', 'P1', 'S1', 'S2'])\n",
    "print(\"%d tidal constituents to be analysed\" % len(wave_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the Dask cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client\n",
    "cluster = KubeCluster()\n",
    "cluster.adapt(minimum=10, maximum=40)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nodal_corrections(client, waves, time_series):\n",
    "    \"\"\"Compute nodal corrections for a given time series\"\"\"\n",
    "    t = time_series.astype('datetime64[s]').astype('float64')\n",
    "    f, v0u = waves.compute_nodal_corrections(t)\n",
    "    return (dask.array.from_delayed(client.scatter(f, broadcast=True),\n",
    "                                    shape=f.shape,\n",
    "                                    dtype=f.dtype),\n",
    "            dask.array.from_delayed(client.scatter(v0u, broadcast=True),\n",
    "                                    shape=v0u.shape,\n",
    "                                    dtype=v0u.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation of nodal corrections for the selected time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, v0u = compute_nodal_corrections(client, wave_table, time_series[period])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faces(ds, face, period, indices=None):\n",
    "    \"\"\"Load a face from the time series\"\"\"\n",
    "    if indices is None:\n",
    "        indices = slice(0, None, 1)\n",
    "    ds = ds.Eta\n",
    "    ds = ds.transpose(\"face\", \"j\", \"i\", \"time\")\n",
    "    return ds.isel(face=face, time=period, i=indices, j=indices).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation takes a little time. In order to make it faster, the processed grid is sub-sampled. If you want to process it completely, replace the following line with:\n",
    "\n",
    "```python\n",
    "indices=None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=slice(0, None, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will analyze the part of the grid representing Europe (`face=2`). Since the tide is strong, near the northwest coast, the effects of the tide in this area can be better illustrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_faces(ssh, face, period, indices=indices)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dask_array_rechunk(da, axis=2):\n",
    "    \"\"\"Search for the optimal block cutting without modifying the axis 'axis'\n",
    "    in order to optimize its access in memory.\"\"\"\n",
    "    nblocks = 1\n",
    "    \n",
    "    def calculate_chuncks_size(chunks, size):\n",
    "        result = np.array(chunks).prod() * size\n",
    "        return result / (1000**2)\n",
    "       \n",
    "    while True:\n",
    "        chunks = []\n",
    "        div = int(np.sqrt(nblocks))\n",
    "        for index, item in enumerate(da.chunks):\n",
    "            chunks.append(np.array(item).sum() * (div if index == axis else 1))\n",
    "        chunks = tuple(item // div for index, item in enumerate(chunks))\n",
    "        chuncks_size = calculate_chuncks_size(chunks, da.dtype.itemsize)\n",
    "        if chuncks_size > 100 and chuncks_size < 150:\n",
    "            return chunks\n",
    "        nblocks += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.rechunk(dask_array_rechunk(ds))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we just have to call the function `dask.array.apply_along_axis`. This function tries to validate the arguments by executing once the function to be vectorized with arbitrary values. However, it does not work here, because one of our parameters is a matrix.  To avoid this problem, the function has been copied and modified in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_along_axis(arr, func1d, func1d_axis, func1d_args, func1d_kwargs):\n",
    "    \"\"\"Wrap apply_along_axis\"\"\"\n",
    "    return np.apply_along_axis(func1d, func1d_axis, arr, *func1d_args,\n",
    "                                  **func1d_kwargs)\n",
    "\n",
    "\n",
    "def apply_along_axis(func1d, axis, arr, *args, **kwargs):\n",
    "    \"\"\"Apply the harmonic analysis to 1-D slices along the given axis.\"\"\"\n",
    "    arr = dask.array.core.asarray(arr)\n",
    "\n",
    "    # Validate and normalize axis.\n",
    "    arr.shape[axis]\n",
    "    axis = len(arr.shape[:axis])\n",
    "\n",
    "    # Rechunk so that analyze is applied over the full axis.\n",
    "    arr = arr.rechunk(arr.chunks[:axis] + (arr.shape[axis:axis + 1], ) +\n",
    "                      arr.chunks[axis + 1:])\n",
    "\n",
    "    # Test out some data with the function.\n",
    "    test_data = np.ones(args[0].shape[1], dtype=arr.dtype)\n",
    "    test_result = np.array(func1d(test_data, *args, **kwargs))\n",
    "\n",
    "    # Map analyze over the data to get the result\n",
    "    # Adds other axes as needed.\n",
    "    result = arr.map_blocks(\n",
    "        _apply_along_axis,\n",
    "        name=dask.utils.funcname(func1d) + '-along-axis',\n",
    "        dtype=test_result.dtype,\n",
    "        chunks=(arr.chunks[:axis] + test_result.shape + arr.chunks[axis + 1:]),\n",
    "        drop_axis=axis,\n",
    "        new_axis=list(range(axis, axis + test_result.ndim, 1)),\n",
    "        func1d=func1d,\n",
    "        func1d_axis=axis,\n",
    "        func1d_args=args,\n",
    "        func1d_kwargs=kwargs,\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we perform our harmonic analysis on the face of the model loaded in memory.\n",
    "\n",
    "*Note: To analyze the entire time series, we would have to loop on the 13 faces storing the different geographical areas of the Earth.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = apply_along_axis(pytide.WaveTable.harmonic_analysis, 2, ds,\n",
    "                          *(f, v0u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = future.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result tensor is arranged in order to place the estimated tidal waves on the first dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = np.transpose(analysis, [2, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the amplitude and phase calculated for the M2 wave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tide present in the model is now calculated to correct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = np.absolute(analysis[0, :, :])\n",
    "pha = np.angle(analysis[0, :, :], deg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, (ax_pha, ax_amp) = plt.subplots(1, 2, figsize=(24, 8))\n",
    "\n",
    "c = ax_pha.pcolormesh(pha, vmin=-180, vmax=180, cmap='bwr')\n",
    "fig.colorbar(c, ax=ax_pha)\n",
    "ax_pha.set_title(\"M2 phase (deg)\")\n",
    "\n",
    "c = ax_amp.pcolormesh(amp, vmin=-0.15, vmax=2, cmap='jet')\n",
    "fig.colorbar(c, ax=ax_amp)\n",
    "ax_amp.set_title(\"M2 amplitude (m)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del amp\n",
    "del pha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwaves, ni, nj = analysis.shape\n",
    "tide = wave_table.tide_from_mapping(\n",
    "    time_series[0].astype('datetime64[s]').astype('float64'),\n",
    "    analysis.reshape(nwaves, ni*nj)).reshape(ni, nj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ssh = ssh.Eta.sel(face=face, time=time_series[0])[indices, indices]\n",
    "corrected_ssh = total_ssh - tide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figures of the analysis performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "ax1.pcolormesh(total_ssh, cmap='jet')\n",
    "ax1.set_title(\"Total SSH\")\n",
    "ax2.pcolormesh(corrected_ssh, cmap='jet')\n",
    "ax2.set_title(\"SSH corrected\")\n",
    "ax3.pcolormesh(tide, cmap='jet')\n",
    "ax3.set_title(\"Tide estimated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
